# XRAISE â€” Explainable AI for Railway Safety Evaluations

![Python Version](https://img.shields.io/badge/python-3.11-blue.svg)
![Project Status](https://img.shields.io/badge/status-active-brightgreen.svg)

**XRAISE** (Explainable AI for Railway Safety Evaluations) is a research project by the **Deutsches Zentrum fÃ¼r Schienenverkehrsforschung (DZSF)** at the **Eisenbahn-Bundesamt**.  
This repository contains the source code for training convolutional neural networks on a custom dataset and applying various explainable AI (XAI) methods to support safety evaluations in the railway domain.

---

## ğŸ“˜ Overview

This repository provides:

- Training code for three convolutional neural network architectures:
  - **VGG16** [Simonyan & Zisserman, 2015]
  - **ResNet50** [He et al., 2016]
  - **ConvNeXt-T** [Liu et al., 2022]
- Implementations of four XAI methods:
  - **Grad-CAM (Gradient-weighted Class Activation Mapping)** [Selvaraju et al., 2017]
  - **LRP (Layer-wise Relevance Propagation)** [Bach et al., 2015]
  - **CRAFT (Concept Recursive Activation FacTorization)** [Fel et al., 2015]
  - **CRP (Concept Relevance Propagation)** [Achtibat et al., 2015]
- A `requirements.txt` file for setting up the Python environment.

---

## ğŸ“ Repository Structure

```
XRAISE/
â”‚
â”œâ”€â”€ Code/
â”‚   â”œâ”€â”€ VGG16/
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â”œâ”€â”€ helper.py
â”‚   â”‚   â””â”€â”€ [XAI method scripts]
â”‚   â”‚
â”‚   â”œâ”€â”€ ResNet50/
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â”œâ”€â”€ helper.py
â”‚   â”‚   â””â”€â”€ [XAI method scripts]
â”‚   â”‚
â”‚   â”œâ”€â”€ ConvNeXt-T/
â”‚       â”œâ”€â”€ training.py
â”‚       â”œâ”€â”€ helper.py
â”‚       â””â”€â”€ [XAI method scripts]
â”‚
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ [datasets and preprocessing files]
â”‚
â””â”€â”€ requirements.txt
```

---

## ğŸ§© Environment Setup

To reproduce the experiments and run the code, we recommend using **Python 3.11** in a virtual environment.

### 1. Create and activate a virtual environment

**Windows**

```bash
python -m venv venv
venv\Scripts\activate
```

**macOS / Linux**

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Usage Instructions

*(To be completed â€” usage examples and run commands will be added later.)*

### Currently working XAI/model-combinations:
| Model       | Grad-CAM | LRP    | CRAFT | CRP |
|--------------|-------- |--------|-----------|-----|
| VGG16        |   âœ…   |   âœ…     | âœ…      |  âœ…   |
| ResNet50     |   âœ…   |  âŒ  | âœ…        |  âœ…    |
| ConvNeXt-T   |   âœ…   |   âŒ  | âœ…        |   âŒ  |

---

## ğŸ§  Citation

If you use this repository or parts of it in your work, please cite this github repository appropriately.

---

## ğŸ“š References

### Model Architectures

- VGG16: Simonyan, K. & Zisserman, A. (2015). Very Deep Convolutional Networks for Large-Scale Image Recognition.
- ResNet: He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep Residual Learning for Image Recognition.
- ConvNeXt: Liu, Z., Mao, H., Wu, C.-Y., Feichtenhofer, C., Darrell, T., & Xie, S. (2022). A ConvNet for the 2020s.

### XAI Methods

- Grad-CAM: Selvaraju, Ramprasaath R., et al. â€œGrad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization.â€ 2017 IEEE International Conference on Computer Vision (ICCV), 2017, pp. 618â€“626.
- LRP: Sebastian Bach, Alexander Binder, GrÃ©goire Montavon, Frederick Klauschen, Klaus-Robert MÃ¼ller, and Wojciech Samek. â€œOn Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation.â€ PLoS ONE, vol. 10, no. 7, 2015, e0130140.
- CRAFT: Thomas Fel, Agustin Picard, Louis Bethune, Thibaut Boissin, David Vigouroux, Julien Colin, RÃ©mi CadÃ¨ne, and Thomas Serre. â€œCRAFT: Concept Recursive Activation FactoriÂ­zation for Explainability.â€ Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
- CRP: Reduan Achtibat, Maximilian Dreyer, Ilona Eisenbraun, Sebastian Bosse, Thomas Wiegand, Wojciech Samek, and Sebastian Lapuschkin. â€œFrom Attribution Maps to Humanâ€Understandable Explanations through Concept Relevance Propagation.â€ Nature Machine Intelligence, vol. 5, no. 9, 2023, pp. 1006â€“1019.

---

## ğŸ“„ Acknowledgment
This work is part of the **XRAISE** research project by the  
**Deutsches Zentrum fÃ¼r Schienenverkehrsforschung (DZSF)** at the **Eisenbahn-Bundesamt**.

---
